{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Embedding Comparison for Multi-label Text Classification\n",
        "\n",
        "This notebook trains a simple PyTorch feed-forward network on dense embeddings\n",
        "from four methods: **Word2Vec**, **GloVe**, **FastText**, and **BERT (Sentence-Transformer)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\ahmed\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec, KeyedVectors, FastText\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Config\n",
        "DATA_CSV = \"C:\\\\Deep learning Lab\\\\Dataset\\\\Consumer Review of Clothing Product\\\\data_amazon.xlsx - Sheet1.csv\"  # <-- put Kaggle CSV here\n",
        "GLOVE_PATH = \"Dataset\\\\glove.6B.100d.txt\" # optional\n",
        "WORD2VEC_BIN = None   # path to GoogleNews binary if you have it\n",
        "FASTTEXT_VEC = None  # path to fasttext .vec if you have it\n",
        "SENT_TRANS_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 6\n",
        "LR = 1e-3\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (49338, 9)\n",
            "Columns: ['Title', 'Review', 'Cons_rating', 'Cloth_class', 'Materials', 'Construction', 'Color', 'Finishing', 'Durability']\n",
            "After dropna, rows: 49338\n"
          ]
        }
      ],
      "source": [
        "# ---------- Load data ----------\n",
        "if not os.path.exists(DATA_CSV):\n",
        "    raise FileNotFoundError(f\"Dataset not found at {DATA_CSV}. Download from Kaggle and place the CSV there.\")\n",
        "df = pd.read_csv(DATA_CSV)\n",
        "print('Dataset shape:', df.shape)\n",
        "print('Columns:', df.columns.tolist())\n",
        "\n",
        "if 'Review Text' in df.columns:\n",
        "    df['text'] = df['Review Text'].astype(str)\n",
        "elif 'Review' in df.columns:\n",
        "    df['text'] = df['Review'].astype(str)\n",
        "else:\n",
        "    # try common alternatives\n",
        "    possible = [c for c in df.columns if 'review' in c.lower()]\n",
        "    if len(possible) > 0:\n",
        "        df['text'] = df[possible[0]].astype(str)\n",
        "        print('Using column', possible[0], 'as text')\n",
        "    else:\n",
        "        raise ValueError('Cannot find a review text column in the CSV.')\n",
        "\n",
        "df = df.dropna(subset=['text']).reset_index(drop=True)\n",
        "print('After dropna, rows:', len(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labels: 0\n",
            "Some label classes: []\n"
          ]
        }
      ],
      "source": [
        "# ---------- Build multi-label targets ----------\n",
        "labels_list = []\n",
        "for _, row in df.iterrows():\n",
        "    lbls = []\n",
        "    if 'Recommended IND' in df.columns:\n",
        "        try:\n",
        "            if int(row.get('Recommended IND', 0)) == 1:\n",
        "                lbls.append('RECOMMEND')\n",
        "        except Exception:\n",
        "            pass\n",
        "    if 'Department Name' in df.columns:\n",
        "        lbls.append('DEPT__' + str(row.get('Department Name', 'UNKNOWN')))\n",
        "    if 'Class Name' in df.columns:\n",
        "        lbls.append('CLASS__' + str(row.get('Class Name', 'UNKNOWN')))\n",
        "    labels_list.append(lbls)\n",
        "\n",
        "mlb = MultiLabelBinarizer(sparse_output=False)\n",
        "Y = mlb.fit_transform(labels_list)\n",
        "print('Number of labels:', Y.shape[1])\n",
        "print('Some label classes:', mlb.classes_[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split sizes: 34536 4934 9868\n",
            "Sample tokenized text: ['absolutely', 'wonderful', 'silky', 'and', 'sexy', 'and', 'comfortable']\n"
          ]
        }
      ],
      "source": [
        "# ---------- Train/Val/Test split & preprocessing ----------\n",
        "train_idx, test_idx = train_test_split(np.arange(len(df)), test_size=0.2, random_state=SEED)\n",
        "train_idx, val_idx = train_test_split(train_idx, test_size=0.125, random_state=SEED)\n",
        "print('Split sizes:', len(train_idx), len(val_idx), len(test_idx))\n",
        "\n",
        "texts = df['text'].tolist()\n",
        "\n",
        "def simple_clean(s):\n",
        "    s = str(s).lower()\n",
        "    s = re.sub(r'\\s+', ' ', s)\n",
        "    s = re.sub(r'[^a-z0-9\\s]', ' ', s)\n",
        "    return s.strip()\n",
        "\n",
        "tokens = [word_tokenize(simple_clean(t)) for t in texts]\n",
        "print('Sample tokenized text:', tokens[0][:20])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Embedding utilities ----------\n",
        "def average_vector(tokens_list, model_dict_or_kv, dim):\n",
        "    vecs = []\n",
        "    for w in tokens_list:\n",
        "        if w in model_dict_or_kv:\n",
        "            vecs.append(model_dict_or_kv[w])\n",
        "    if len(vecs) == 0:\n",
        "        return np.zeros(dim, dtype=np.float32)\n",
        "    return np.mean(vecs, axis=0)\n",
        "\n",
        "def load_glove(glove_path):\n",
        "    emb = {}\n",
        "    with open(glove_path, 'r', encoding='utf8', errors='ignore') as f:\n",
        "        for line in tqdm(f, desc='Loading GloVe'):\n",
        "            parts = line.strip().split()\n",
        "            word = parts[0]\n",
        "            vec = np.array(parts[1:]).astype(np.float32)\n",
        "            emb[word] = vec\n",
        "    dim = len(next(iter(emb.values())))\n",
        "    print('Loaded GloVe dim:', dim)\n",
        "    return emb, dim\n",
        "\n",
        "def build_glove_embeddings(glove_path):\n",
        "    glove_emb, dim = load_glove(glove_path)\n",
        "    embs = np.vstack([average_vector(tok, glove_emb, dim) for tok in tokens])\n",
        "    return embs, dim\n",
        "\n",
        "def train_word2vec(tokens_corpus, size=300, window=5, min_count=2, epochs=10):\n",
        "    model = Word2Vec(sentences=tokens_corpus, vector_size=size, window=window, min_count=min_count, workers=4, epochs=epochs, seed=SEED)\n",
        "    return model\n",
        "\n",
        "def build_word2vec_embeddings(pretrained_bin_path=None, train_on_corpus=True, size=300):\n",
        "    if pretrained_bin_path and os.path.exists(pretrained_bin_path):\n",
        "        print('Loading pretrained Word2Vec KeyedVectors ...')\n",
        "        kv = KeyedVectors.load_word2vec_format(pretrained_bin_path, binary=True)\n",
        "        dim = kv.vector_size\n",
        "        embs = np.vstack([average_vector(tok, kv, dim) for tok in tokens])\n",
        "        return embs, dim\n",
        "    else:\n",
        "        print('Training Word2Vec on corpus...')\n",
        "        w2v = train_word2vec(tokens, size=size)\n",
        "        dim = size\n",
        "        embs = np.vstack([average_vector(tok, w2v.wv, dim) for tok in tokens])\n",
        "        return embs, dim\n",
        "\n",
        "def train_fasttext(tokens_corpus, size=300, window=5, min_count=2, epochs=10):\n",
        "    model = FastText(sentences=tokens_corpus, vector_size=size, window=window, min_count=min_count, workers=4, epochs=epochs, seed=SEED)\n",
        "    return model\n",
        "\n",
        "def build_fasttext_embeddings(pretrained_vec_path=None, train_on_corpus=True, size=300):\n",
        "    if pretrained_vec_path and os.path.exists(pretrained_vec_path):\n",
        "        print('Loading pretrained FastText vectors ...')\n",
        "        kv = KeyedVectors.load_word2vec_format(pretrained_vec_path, binary=False)\n",
        "        dim = kv.vector_size\n",
        "        embs = np.vstack([average_vector(tok, kv, dim) for tok in tokens])\n",
        "        return embs, dim\n",
        "    else:\n",
        "        print('Training FastText on corpus...')\n",
        "        ft = train_fasttext(tokens, size=size)\n",
        "        dim = size\n",
        "        embs = np.vstack([average_vector(tok, ft.wv, dim) for tok in tokens])\n",
        "        return embs, dim\n",
        "\n",
        "def build_bert_embeddings(model_name=SENT_TRANS_MODEL, batch_size=128):\n",
        "    print('Loading SentenceTransformer:', model_name)\n",
        "    sbert = SentenceTransformer(model_name, device=DEVICE)\n",
        "    embeddings = sbert.encode(texts, show_progress_bar=True, batch_size=batch_size, convert_to_numpy=True)\n",
        "    return embeddings, embeddings.shape[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- PyTorch dataset & model ----------\n",
        "class EmbeddingDataset(Dataset):\n",
        "    def __init__(self, X_emb, Y, idxs):\n",
        "        self.X = X_emb[idxs]\n",
        "        self.Y = Y[idxs].astype(np.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, i):\n",
        "        return torch.from_numpy(self.X[i]).float(), torch.from_numpy(self.Y[i]).float()\n",
        "\n",
        "class FeedForwardMLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims=[512,256], output_dim=1, dropout=0.3):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        cur = input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers.append(nn.Linear(cur, h))\n",
        "            layers.append(nn.BatchNorm1d(h))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            cur = h\n",
        "        layers.append(nn.Linear(cur, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Training & evaluation helpers ----------\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "def train_epoch(model, loader, opt, loss_fn):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for Xb, Yb in loader:\n",
        "        Xb, Yb = Xb.to(DEVICE), Yb.to(DEVICE)\n",
        "        opt.zero_grad()\n",
        "        logits = model(Xb)\n",
        "        loss = loss_fn(logits, Yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item() * Xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def eval_model(model, loader, threshold=0.5):\n",
        "    model.eval()\n",
        "    Y_true = []\n",
        "    Y_pred = []\n",
        "    Y_scores = []\n",
        "    with torch.no_grad():\n",
        "        for Xb, Yb in loader:\n",
        "            Xb = Xb.to(DEVICE)\n",
        "            logits = model(Xb)\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "            Y_scores.append(probs)\n",
        "            preds = (probs >= threshold).astype(int)\n",
        "            Y_pred.append(preds)\n",
        "            Y_true.append(Yb.numpy().astype(int))\n",
        "    Y_true = np.vstack(Y_true)\n",
        "    Y_pred = np.vstack(Y_pred)\n",
        "    Y_scores = np.vstack(Y_scores)\n",
        "    f1_micro = f1_score(Y_true, Y_pred, average='micro', zero_division=0)\n",
        "    f1_macro = f1_score(Y_true, Y_pred, average='macro', zero_division=0)\n",
        "    precision = precision_score(Y_true, Y_pred, average='micro', zero_division=0)\n",
        "    recall = recall_score(Y_true, Y_pred, average='micro', zero_division=0)\n",
        "    aucs = []\n",
        "    for i in range(Y_true.shape[1]):\n",
        "        try:\n",
        "            auc = roc_auc_score(Y_true[:,i], Y_scores[:,i])\n",
        "        except Exception:\n",
        "            auc = np.nan\n",
        "        aucs.append(auc)\n",
        "    mean_auc = np.nanmean(aucs)\n",
        "    return dict(f1_micro=f1_micro, f1_macro=f1_macro, precision=precision, recall=recall, mean_auc=mean_auc)\n",
        "\n",
        "def run_experiment(X_emb, emb_name='EMB', input_dim=None, epochs=EPOCHS):\n",
        "    if input_dim is None:\n",
        "        input_dim = X_emb.shape[1]\n",
        "    train_ds = EmbeddingDataset(X_emb, Y, train_idx)\n",
        "    val_ds = EmbeddingDataset(X_emb, Y, val_idx)\n",
        "    test_ds = EmbeddingDataset(X_emb, Y, test_idx)\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = FeedForwardMLP(input_dim=input_dim, hidden_dims=[512,256], output_dim=Y.shape[1], dropout=0.3).to(DEVICE)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    best_val = -np.inf\n",
        "    best_state = None\n",
        "    for ep in range(1, epochs+1):\n",
        "        tr_loss = train_epoch(model, train_loader, opt, loss_fn)\n",
        "        metrics_val = eval_model(model, val_loader)\n",
        "        print(f\"[{emb_name}] Epoch {ep}/{epochs} train_loss={tr_loss:.4f} val_f1={metrics_val['f1_micro']:.4f} val_auc={metrics_val['mean_auc']:.4f}\")\n",
        "        if metrics_val['f1_micro'] > best_val:\n",
        "            best_val = metrics_val['f1_micro']\n",
        "            best_state = model.state_dict()\n",
        "    model.load_state_dict(best_state)\n",
        "    metrics_test = eval_model(model, test_loader)\n",
        "    print(f\"[{emb_name}] TEST: f1_micro={metrics_test['f1_micro']:.4f}, f1_macro={metrics_test['f1_macro']:.4f}, mean_auc={metrics_test['mean_auc']:.4f}\")\n",
        "    return metrics_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Y has zero columns. Rebuilding labels from available dataframe columns ('Cloth_class' and 'Cons_rating')...\n",
            "Rebuilt labels. Number of labels: 26 Some classes: ['CLASS__Blazer' 'CLASS__Blouses' 'CLASS__Casual bottoms'\n",
            " 'CLASS__Chemises' 'CLASS__Dress' 'CLASS__Dresses' 'CLASS__Fine gauge'\n",
            " 'CLASS__Intimates' 'CLASS__Jackets' 'CLASS__Jeans']\n",
            "Recomputed split sizes: 34536 4934 9868\n",
            "GloVe not found at Dataset\\glove.6B.100d.txt\n",
            "\n",
            "Word2Vec (trained on corpus or loaded pretrained if path set)\n",
            "Training Word2Vec on corpus...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Word2Vec] Epoch 1/6 train_loss=0.1367 val_f1=0.6495 val_auc=0.8226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Word2Vec] Epoch 2/6 train_loss=0.1098 val_f1=0.6654 val_auc=0.8471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Word2Vec] Epoch 3/6 train_loss=0.1059 val_f1=0.6697 val_auc=0.8671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Word2Vec] Epoch 4/6 train_loss=0.1036 val_f1=0.6797 val_auc=0.8694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Word2Vec] Epoch 5/6 train_loss=0.1016 val_f1=0.6837 val_auc=0.8783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Word2Vec] Epoch 6/6 train_loss=0.1004 val_f1=0.6851 val_auc=0.8912\n",
            "[Word2Vec] TEST: f1_micro=0.6809, f1_macro=0.2488, mean_auc=0.8465\n",
            "\n",
            "FastText (trained on corpus or loaded pretrained if path set)\n",
            "Training FastText on corpus...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FastText] Epoch 1/6 train_loss=0.1452 val_f1=0.6113 val_auc=0.8154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FastText] Epoch 2/6 train_loss=0.1186 val_f1=0.6287 val_auc=0.8453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FastText] Epoch 3/6 train_loss=0.1140 val_f1=0.6396 val_auc=0.8457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FastText] Epoch 4/6 train_loss=0.1114 val_f1=0.6469 val_auc=0.8666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FastText] Epoch 5/6 train_loss=0.1095 val_f1=0.6596 val_auc=0.8741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FastText] Epoch 6/6 train_loss=0.1078 val_f1=0.6591 val_auc=0.8806\n",
            "[FastText] TEST: f1_micro=0.6591, f1_macro=0.1733, mean_auc=0.8323\n",
            "\n",
            "BERT / SentenceTransformer\n",
            "Loading SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ahmed\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Batches: 100%|██████████| 771/771 [07:22<00:00,  1.74it/s]\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BERT-SBERT] Epoch 1/6 train_loss=0.1161 val_f1=0.7299 val_auc=0.8860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BERT-SBERT] Epoch 2/6 train_loss=0.0904 val_f1=0.7352 val_auc=0.9015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BERT-SBERT] Epoch 3/6 train_loss=0.0867 val_f1=0.7379 val_auc=0.9143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BERT-SBERT] Epoch 4/6 train_loss=0.0841 val_f1=0.7391 val_auc=0.9171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BERT-SBERT] Epoch 5/6 train_loss=0.0821 val_f1=0.7422 val_auc=0.9286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "c:\\Data Analytics\\Data_Analytics_Env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BERT-SBERT] Epoch 6/6 train_loss=0.0799 val_f1=0.7432 val_auc=0.9279\n",
            "[BERT-SBERT] TEST: f1_micro=0.7419, f1_macro=0.4051, mean_auc=0.8861\n",
            "\n",
            "Results summary:\n",
            "    embedding  dim  f1_micro  f1_macro  precision    recall  mean_auc\n",
            "2  BERT-SBERT  384  0.741893  0.405114   0.830700  0.670241  0.886084\n",
            "0    Word2Vec  300  0.680893  0.248843   0.854617  0.565865  0.846452\n",
            "1    FastText  300  0.659110  0.173262   0.856032  0.535845  0.832269\n",
            "\n",
            "Saved results to embedding_comparison_results.csv\n"
          ]
        }
      ],
      "source": [
        "# ---------- Run experiments (GloVe, Word2Vec, FastText, BERT) ----------\n",
        "results = []\n",
        "\n",
        "# If Y has zero columns (no labels were created earlier), try to build sensible labels\n",
        "if Y.shape[1] == 0:\n",
        "    print(\"Y has zero columns. Rebuilding labels from available dataframe columns ('Cloth_class' and 'Cons_rating')...\")\n",
        "    labels_list = []\n",
        "    for _, row in df.iterrows():\n",
        "        lbls = []\n",
        "        if 'Cloth_class' in df.columns and pd.notna(row.get('Cloth_class')):\n",
        "            lbls.append('CLASS__' + str(row.get('Cloth_class')))\n",
        "        if 'Cons_rating' in df.columns and pd.notna(row.get('Cons_rating')):\n",
        "            try:\n",
        "                if float(row.get('Cons_rating')) >= 4.0:\n",
        "                    lbls.append('RATING_GE4')\n",
        "            except Exception:\n",
        "                pass\n",
        "        # ensure at least one label per sample to avoid empty rows for MultiLabelBinarizer\n",
        "        if len(lbls) == 0:\n",
        "            lbls.append('NO_LABEL')\n",
        "        labels_list.append(lbls)\n",
        "    mlb = MultiLabelBinarizer(sparse_output=False)\n",
        "    Y = mlb.fit_transform(labels_list)\n",
        "    print('Rebuilt labels. Number of labels:', Y.shape[1], 'Some classes:', mlb.classes_[:10])\n",
        "\n",
        "    # recompute splits because label matrix changed (optional but safer)\n",
        "    train_idx, test_idx = train_test_split(np.arange(len(df)), test_size=0.2, random_state=SEED)\n",
        "    train_idx, val_idx = train_test_split(train_idx, test_size=0.125, random_state=SEED)\n",
        "    print('Recomputed split sizes:', len(train_idx), len(val_idx), len(test_idx))\n",
        "\n",
        "# Helper to safely try an experiment and continue on error\n",
        "def try_run(name, build_fn, *build_args, **build_kwargs):\n",
        "    try:\n",
        "        X_emb, dim = build_fn(*build_args, **build_kwargs)\n",
        "        metrics = run_experiment(X_emb, emb_name=name, input_dim=dim)\n",
        "        results.append({'embedding': name, 'dim': dim, **metrics})\n",
        "    except Exception as e:\n",
        "        print(f\"[{name}] Failed: {e}\")\n",
        "\n",
        "# 1) GloVe (optional)\n",
        "if os.path.exists(GLOVE_PATH):\n",
        "    print('Building GloVe embeddings...')\n",
        "    try_run('GloVe', build_glove_embeddings, GLOVE_PATH)\n",
        "else:\n",
        "    print('GloVe not found at', GLOVE_PATH)\n",
        "\n",
        "# 2) Word2Vec (train on corpus or load if provided)\n",
        "print('\\nWord2Vec (trained on corpus or loaded pretrained if path set)')\n",
        "try:\n",
        "    X_w2v, dim_w2v = build_word2vec_embeddings(pretrained_bin_path=WORD2VEC_BIN, train_on_corpus=True, size=300)\n",
        "    res_w2v = run_experiment(X_w2v, emb_name='Word2Vec', input_dim=dim_w2v)\n",
        "    results.append({'embedding':'Word2Vec','dim':dim_w2v, **res_w2v})\n",
        "except Exception as e:\n",
        "    print('[Word2Vec] Failed:', e)\n",
        "\n",
        "# 3) FastText (train on corpus or load if provided)\n",
        "print('\\nFastText (trained on corpus or loaded pretrained if path set)')\n",
        "try:\n",
        "    X_ft, dim_ft = build_fasttext_embeddings(pretrained_vec_path=FASTTEXT_VEC, train_on_corpus=True, size=300)\n",
        "    res_ft = run_experiment(X_ft, emb_name='FastText', input_dim=dim_ft)\n",
        "    results.append({'embedding':'FastText','dim':dim_ft, **res_ft})\n",
        "except Exception as e:\n",
        "    print('[FastText] Failed:', e)\n",
        "\n",
        "# 4) BERT / SentenceTransformer\n",
        "print('\\nBERT / SentenceTransformer')\n",
        "try:\n",
        "    X_bert, dim_bert = build_bert_embeddings(batch_size=64)\n",
        "    res_bert = run_experiment(X_bert, emb_name='BERT-SBERT', input_dim=dim_bert)\n",
        "    results.append({'embedding':'BERT-SBERT','dim':dim_bert, **res_bert})\n",
        "except Exception as e:\n",
        "    print('[BERT-SBERT] Failed:', e)\n",
        "\n",
        "# Summarize results (if any succeeded)\n",
        "if len(results) > 0:\n",
        "    df_res = pd.DataFrame(results)\n",
        "    print('\\nResults summary:')\n",
        "    print(df_res.sort_values('f1_micro', ascending=False))\n",
        "    df_res.to_csv('embedding_comparison_results.csv', index=False)\n",
        "    print('\\nSaved results to embedding_comparison_results.csv')\n",
        "else:\n",
        "    print('No experiment completed successfully. Check earlier errors.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Data_Analytics_Env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
